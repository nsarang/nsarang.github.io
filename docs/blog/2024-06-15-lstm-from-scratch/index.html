<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.55">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nima Sarang">
<meta name="dcterms.date" content="2024-06-15">
<meta name="description" content="This tutorial walks through the implementation of a multi-layer LSTM model from scratch in pure NumPy, and trains it on the Shakespeare dataset. It also covers the implementation of the AdamW optimizer and the necessary data modules.">

<title>Implementing Multi-Layer LSTM and AdamW from Scratch using NumPy â€“ Nima Sarang</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../_assets/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-HWSGHN8N8N"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-HWSGHN8N8N', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@300;400;700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Petrona:wght@400;500&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Red+Hat+Text:ital,wght@0,400;0,500;1,400;1,500&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=B612:ital,wght@0,400;0,700;1,400;1,700&amp;family=B612+Mono:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">

<link href="https://fonts.googleapis.com/css2?family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:ital,opsz,wght@0,8..60,200..900;1,8..60,200..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
<meta property="og:title" content="Implementing Multi-Layer LSTM and AdamW from Scratch using NumPy">
<meta property="og:description" content="This tutorial walks through the implementation of a multi-layer LSTM model from scratch in pure NumPy, and trains it on the Shakespeare dataset. It also covers the implementation of the AdamW optimizer and the necessary data modules.">
<meta property="og:image" content="https://www.nimasarang.com/blog/2024-06-15-lstm-from-scratch/featured.png">
<meta property="og:site_name" content="Nima Sarang">
<meta property="og:image:height" content="503">
<meta property="og:image:width" content="890">
<meta name="twitter:title" content="Implementing Multi-Layer LSTM and AdamW from Scratch using NumPy">
<meta name="twitter:description" content="This tutorial walks through the implementation of a multi-layer LSTM model from scratch in pure NumPy, and trains it on the Shakespeare dataset. It also covers the implementation of the AdamW optimizer and the necessary data modules.">
<meta name="twitter:image" content="https://www.nimasarang.com/blog/2024-06-15-lstm-from-scratch/featured.png">
<meta name="twitter:image-height" content="503">
<meta name="twitter:image-width" content="890">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../_assets/favicon.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Nima Sarang</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../project/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publication/index.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://www.github.com/nsarang" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/nima-sarang" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns">
<div id="title-block-header-title" class="quarto-title page-columns page-full page-layout-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg); background-repeat: no-repeat;">
<h1 class="title">Implementing Multi-Layer LSTM and AdamW from Scratch using NumPy</h1>
    <div class="quarto-categories">
        <div class="quarto-category">ML</div>
        <div class="quarto-category">NLP</div>
        <div class="quarto-category">Optimization</div>
        <div class="quarto-category">Analysis</div>
      </div>
  </div>

<div>
  <div id="title-block-title-desc" class="description pt-4">
    This tutorial walks through the implementation of a multi-layer LSTM model from scratch in pure NumPy, and trains it on the Shakespeare dataset. It also covers the implementation of the AdamW optimizer and the necessary data modules.
  </div>
</div>


<div class="quarto-title-meta column-body">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nima Sarang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 15, 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">October 10, 2024</p>
    </div>
  </div>
    
  </div>
  



</header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#multi-layer-lstm" id="toc-multi-layer-lstm" class="nav-link" data-scroll-target="#multi-layer-lstm"><span class="header-section-number">2</span> Multi-Layer LSTM</a></li>
  <li><a href="#activation-and-loss-functions" id="toc-activation-and-loss-functions" class="nav-link" data-scroll-target="#activation-and-loss-functions"><span class="header-section-number">3</span> Activation and Loss Functions</a></li>
  <li><a href="#adamw" id="toc-adamw" class="nav-link" data-scroll-target="#adamw"><span class="header-section-number">4</span> AdamW</a></li>
  <li><a href="#data-utilities" id="toc-data-utilities" class="nav-link" data-scroll-target="#data-utilities"><span class="header-section-number">5</span> Data Utilities</a></li>
  <li><a href="#training-on-shakespeare-dataset" id="toc-training-on-shakespeare-dataset" class="nav-link" data-scroll-target="#training-on-shakespeare-dataset"><span class="header-section-number">6</span> Training on Shakespeare dataset</a>
  <ul class="collapse">
  <li><a href="#load" id="toc-load" class="nav-link" data-scroll-target="#load"><span class="header-section-number">6.1</span> Load</a></li>
  <li><a href="#preprocess" id="toc-preprocess" class="nav-link" data-scroll-target="#preprocess"><span class="header-section-number">6.2</span> Preprocess</a></li>
  <li><a href="#initialize" id="toc-initialize" class="nav-link" data-scroll-target="#initialize"><span class="header-section-number">6.3</span> Initialize</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop"><span class="header-section-number">6.4</span> Training loop</a></li>
  <li><a href="#generating-text" id="toc-generating-text" class="nav-link" data-scroll-target="#generating-text"><span class="header-section-number">6.5</span> Generating text</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">
<style>
  body {
    visibility: hidden; /* initially hidden until DOM ready to prevent flicker */
  }
</style>
<noscript>
  <style>
    body {
      visibility: visible !important; /* Override hidden state when JS is disabled */
    }
  </style>
</noscript>

<!-- source: https://github.com/gadenbuie/garrickadenbuie-com/blob/main/_partials/title-block-link-buttons/title-block.html -->
<!-- 
<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title"> 
-->
<!-- <header id="title-block-header" class="quarto-title-block default page-columns"> -->
<!-- <div class="quarto-title page-columns page-full featured-image p-4" style="background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);"> -->



<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>When I started writing this post, my goal was to refresh my knowledge of LSTMs by implementing one from scratch. I was initially tempted to use PyTorch or Karpathyâ€™s <a href="https://github.com/karpathy/micrograd">micrograd</a>, but since I also wanted to implement the backpropagation part myself without relying on an autograd engine, I decided to go with NumPy. This choice meant that the optimizer and training loop would also have to be implemented in NumPy, turning the project into a comprehensive deep dive. So here we are ðŸ˜…</p>
<p>On the bright side, itâ€™s been a great learning experience. Iâ€™ve refreshed my understanding of computational graphs, gradient accumulation in recurrent models, and the inner workings of the Adam optimizer. In this post, Iâ€™ll walk you through the implementation which resembles a PyTorch-like API. The areas covered are:</p>
<ul>
<li>Multi-layer LSTM Model<br>
</li>
<li>AdamW Optimizer<br>
</li>
<li>Dataset and Dataloader<br>
</li>
<li>Training on the Shakespeare dataset</li>
</ul>
<p><br> Iâ€™ll be using a similar presentation style to <a href="https://nn.labml.ai/transformers/mha.html">labml.ai</a> since itâ€™s much easier to follow the code when the explanation is right beside it. Be sure to check out their website for some cool implementations if you havenâ€™t already.</p>
<p>I hope youâ€™ll find this post helpful. ðŸ˜Ž<br>
P.S. You can toggle between light and dark mode through the button at the top right corner.</p>
</section>
<section id="multi-layer-lstm" class="level2 page-columns page-full" data-number="2">
<h2 data-number="2" data-anchor-id="multi-layer-lstm"><span class="header-section-number">2</span> Multi-Layer LSTM</h2>
<p>Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) architecture specifically designed to handle long-term dependencies in sequential data. It incorporates a memory state, a hidden state, and three gating mechanisms: the input gate, forget gate, and output gate. These gates control the flow of information into, out of, and within the memory and hidden states, allowing the LSTM to selectively remember or forget information at each time step.</p>
<p>The memory state in an LSTM acts as a long-term storage unit, allowing the network to retain information over long sequences. The input gate determines how much new information should be stored in the memory state, while the forget gate controls the amount of old information to be discarded. The output gate regulates the flow of information from the memory state and hidden state to the next time step.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/lstm-cell.webp" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>LSTM Architecture <span class="citation" data-cites="colah2015_lstm_architecture"><a href="#ref-colah2015_lstm_architecture" role="doc-biblioref">[1]</a></span></figcaption>
</figure>
</div>
<p>The LSTM cell consists of the following components: <span class="math display">\[
\begin{aligned}
f_t &amp;= \sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf}) \\
i_t &amp;= \sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi}) \\
o_t &amp;= \sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho}) \\
\tilde{C}_t &amp;= \tanh(W_{ic}x_t + b_{ic} + W_{hc}h_{t-1} + b_{hc}) \\
C_t &amp;= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t \\
h_t &amp;= o_t \odot \tanh(C_t)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(f_t\)</span>, <span class="math inline">\(i_t\)</span>, and <span class="math inline">\(o_t\)</span> are the forget, input, and output gates, respectively. <span class="math inline">\(\tilde{C}_t\)</span> is the candidate memory state, <span class="math inline">\(C_t\)</span> is the memory state, and <span class="math inline">\(h_t\)</span> is the hidden state at time step <span class="math inline">\(t\)</span>. <span class="math inline">\(x_t\)</span> is the input at time step <span class="math inline">\(t\)</span>, <span class="math inline">\(h_{t-1}\)</span> is the hidden state at time step <span class="math inline">\(t-1\)</span>, and <span class="math inline">\(W\)</span> and <span class="math inline">\(b\)</span> are the weights and biases of each gate.</p>
<section id="cifg-lstm" class="level4">
<h4 data-anchor-id="cifg-lstm">CIFG LSTM</h4>
<p>In this post, weâ€™ll implement a special of type of LSTM called <strong>Coupled Input and Forget Gate (CIFG)</strong> <span class="citation" data-cites="Greff_2017"><a href="#ref-Greff_2017" role="doc-biblioref">[2]</a></span>. In CIFG LSTM, the input gate is computed as: <span class="math display">\[i_t = 1 - f_t\]</span> This reduces the number of parameters in the model and has been shown to perform well in practice.</p>
</section>
<section id="multi-layers" class="level4 page-columns page-full">
<h4>Multi-layers</h4>
<p>A multi-layer LSTM is simply stacking multiple LSTM cells on top of each other. The output of the previous LSTM cell is fed as input to the next LSTM cell. The hidden state of the last LSTM cell is the input to the classification layer.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/multilayer_lstm.png" class="img-fluid figure-img" style="width:30.0%"></p>
<figcaption>Multi-layer LSTM Example <span class="citation" data-cites="cs231n_rnn"><a href="#ref-cs231n_rnn" role="doc-biblioref">[3]</a></span>. Each row of the green rectangles represent an LSTM cell.</figcaption>
</figure>
</div>
<p>Now letâ€™s get into the implementation, step by step.</p>
<div id="cell-6" class="cell page-columns page-full" data-execution_count="4">
<div class="cell-output cell-output-display column-page">
<h3 data-anchor-id="multi-layers">lstm.py</h3>
        <div class="docfuse ">
            
        <div class="section" id="lstm-0">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-0">#</a>
                </div>
                <p>Import the dependencies.  <br>
The activation functions are defined in a separate module</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">1</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos">2</span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="linenos">3</span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="linenos">4</span><span class="kn">from</span> <span class="nn">op</span> <span class="kn">import</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">tanh</span><span class="p">,</span> <span class="n">softmax</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-1">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-1">#</a>
                </div>
                <h3>LSTM Classifier</h3>
<p>Multi-layer LSTM classifier for sequence classification tasks.</p>
<p>It consists of an embedding layer, multiple LSTM cells, and a classification head.
The model is used to process input sequences and generate output logits.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">5</span><span class="k">class</span> <span class="nc">LSTMClassifier</span><span class="p">:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-2">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-2">#</a>
                </div>
                <ul>
<li><code>embed_size</code>: Dimension of the word embeddings, or more generally, the input features.</li>
<li><code>hidden_size</code>: The size of the hidden state of the LSTM cells.</li>
<li><code>vocab_size</code>: The number of unique tokens in the vocabulary.</li>
<li><code>n_cells</code>: Number of stacked LSTM cells in the model.</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos"> 6</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 7</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 8</span>        <span class="n">embed_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 9</span>        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="linenos">10</span>        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="linenos">11</span>        <span class="n">n_cells</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-3">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-3">#</a>
                </div>
                <p>Define internal variables</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">13</span>        <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
<span class="linenos">14</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
<span class="linenos">15</span>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
<span class="linenos">16</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span> <span class="o">=</span> <span class="n">n_cells</span>
<span class="linenos">17</span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-4">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-4">#</a>
                </div>
                <p>Create embedding layer to convert word indices to embeddings</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">18</span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">))</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-5">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-5">#</a>
                </div>
                <p>Create LSTM layers</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">19</span>        <span class="k">for</span> <span class="n">cell_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cells</span><span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-6">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-6">#</a>
                </div>
                <p>For every <code>forget</code>, <code>output</code>, and <code>cell</code> gates, create a linear layer</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">20</span>            <span class="k">for</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"f"</span><span class="p">,</span> <span class="s2">"o"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">]:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-7">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-7">#</a>
                </div>
                <p>The input size of the first layer is <code>embed_size</code> + <code>hidden_size</code>, since the input is the concatenation of the input features and the previous hidden state. For subsequent layers, the input size is 2 x <code>hidden_size</code>.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">21</span>                <span class="n">linp_sz</span> <span class="o">=</span> <span class="n">hidden_size</span> <span class="o">+</span> <span class="p">(</span>
<span class="linenos">22</span>                    <span class="n">embed_size</span> <span class="k">if</span> <span class="n">cell_index</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">hidden_size</span>
<span class="linenos">23</span>                <span class="p">)</span>
<span class="linenos">24</span>                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"W</span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cell_index</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty</span><span class="p">(</span>
<span class="linenos">25</span>                    <span class="p">(</span><span class="n">linp_sz</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<span class="linenos">26</span>                <span class="p">)</span>
<span class="linenos">27</span>                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"b</span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cell_index</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty</span><span class="p">(</span>
<span class="linenos">28</span>                    <span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
<span class="linenos">29</span>                <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-8">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-8">#</a>
                </div>
                <p>Classification head (projection layer) to generate logits</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">30</span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"W_head"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
<span class="linenos">31</span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"b_head"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">))</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-9">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-9">#</a>
                </div>
                <p>Create the gradient arrays. These will be used to store the gradients during backpropagation.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">32</span>        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">empty_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-10">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-10">#</a>
                </div>
                <p>Initialize the weights</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">33</span>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-11">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-11">#</a>
                </div>
                <p>Calculate the total number of parameters in the model.
The <code>size</code> property of a numpy array returns the number of elements in the array.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">34</span>    <span class="nd">@property</span>
<span class="linenos">35</span>    <span class="k">def</span> <span class="nf">num_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">36</span>        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">size</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">values</span><span class="p">())</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-12">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-12">#</a>
                </div>
                <p><strong>Glorot/Xavier initialization</strong></p>
<p>The weights are initialized from a uniform distribution in the range \([-d, d]\), where
\(d = \sqrt{\frac{6.0}{(r + c)}}\), and \(r\) and \(c\) are the number of rows and columns
in the weight matrix. This makes the variance of the weights inversely proportional to the
number the units, and helps in preventing the gradients from vanishing or exploding during
training. The biases are initialized to zero.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">37</span>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">38</span>        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span class="linenos">39</span>            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">40</span>                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">((</span><span class="n">layer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="linenos">41</span>            <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<span class="linenos">42</span>                <span class="n">r</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">shape</span>
<span class="linenos">43</span>                <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">sqrt</span><span class="p">(</span><span class="mf">6.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="n">c</span><span class="p">))</span>
<span class="linenos">44</span>                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-13">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-13">#</a>
                </div>
                <p>Initialize the hidden and cell states for the LSTM layers.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">45</span>    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="linenos">46</span>        <span class="n">state</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-14">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-14">#</a>
                </div>
                <p>For every LSTM cell and every sample in the batch, initialize the hidden and cell states to zeros.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">47</span>        <span class="n">state</span><span class="p">[</span><span class="s2">"h"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
<span class="linenos">48</span>        <span class="n">state</span><span class="p">[</span><span class="s2">"c"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
<span class="linenos">49</span>        <span class="k">return</span> <span class="n">state</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-15">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-15">#</a>
                </div>
                <p>Forward pass through the LSTM model.</p>
<ul>
<li><code>inputs</code>: Input sequences of shape (batch_size, seq_len, features)</li>
<li><code>state</code>: Hidden and cell states of the LSTM layers. If None, initialize the states to zeros.</li>
<li><code>teacher_forcing</code>: If True, use <code>inputs</code> as the input at each timestep.
If False, <code>inputs</code> is used as the prefix.</li>
<li><code>generation_length</code>: Length of the generated sequence when <code>teacher_forcing</code> is False.</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">50</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<span class="linenos">51</span>        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generation_length</span><span class="o">=</span><span class="mi">0</span>
<span class="linenos">52</span>    <span class="p">):</span>
<span class="linenos">53</span>        <span class="n">batch_sz</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="linenos">54</span>
<span class="linenos">55</span>        <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
<span class="linenos">56</span>            <span class="k">assert</span> <span class="n">generation_length</span> <span class="o">==</span> <span class="mi">0</span>
<span class="linenos">57</span>
<span class="linenos">58</span>        <span class="n">n_timestamps</span> <span class="o">=</span> <span class="n">seq_len</span> <span class="o">+</span> <span class="n">generation_length</span>
<span class="linenos">59</span>        <span class="n">activations</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">))</span>
<span class="linenos">60</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">((</span><span class="n">batch_sz</span><span class="p">,</span> <span class="n">n_timestamps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>
<span class="linenos">61</span>
<span class="linenos">62</span>        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">63</span>            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">batch_sz</span><span class="p">)</span>
<span class="linenos">64</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">65</span>            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># make a shallow copy</span>
<span class="linenos">66</span>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"h"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">]:</span>
<span class="linenos">67</span>            <span class="n">activations</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="linenos">68</span>
<span class="linenos">69</span>        <span class="k">for</span> <span class="n">timestep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_timestamps</span><span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-16">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-16">#</a>
                </div>
                <p>If teacher forcing is False and the prefix is consumed, use the previous prediction as the input
for the next timestep</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">70</span>            <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">timestep</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">71</span>                <span class="n">word_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">[:,</span> <span class="n">timestep</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">72</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">73</span>                <span class="n">word_indices</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="n">timestep</span><span class="p">]</span>
<span class="linenos">74</span>            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">][</span><span class="n">word_indices</span><span class="p">]</span>
<span class="linenos">75</span>            <span class="n">activations</span><span class="p">[</span><span class="s2">"input"</span><span class="p">][</span><span class="n">timestep</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_indices</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-17">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-17">#</a>
                </div>
                <p>Forward pass through the LSTM cells</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">76</span>            <span class="k">for</span> <span class="n">cell_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-18">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-18">#</a>
                </div>
                <p>Previous cell states</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">77</span>                <span class="n">h_prev</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"h"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span>
<span class="linenos">78</span>                <span class="n">c_prev</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"c"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-19">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-19">#</a>
                </div>
                <p>Concatenate the input features and the previous hidden state</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">79</span>                <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">concatenate</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">h_prev</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-20">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-20">#</a>
                </div>
                <p>Apply the gates, which are linear operations followed by activation functions</p>
<p>\(
\begin{aligned}
f_t &amp;= \sigma(W_{if}x_t + b_{if} \;+\; W_{hf}h_{t-1} + b_{hf}) \\[1ex]
i_t &amp;= 1 - f_t \qquad\qquad \text{Coupled forget and input gates} \\[1ex]
o_t &amp;= \sigma(W_{io}x_t + b_{io} \;+\; W_{ho}h_{t-1} + b_{ho}) \\[1ex]
\tilde{C}_t &amp;= \tanh(W_{ic}x_t + b_{ic} \;+\; W_{hc}h_{t-1} + b_{hc}) \\[1ex]
\end{aligned}
\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">80</span>                <span class="n">f</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span>
<span class="linenos">81</span>                    <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"Wf_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">82</span>                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"bf_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">83</span>                <span class="p">)</span>
<span class="linenos">84</span>                <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">f</span>
<span class="linenos">85</span>                <span class="n">o</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span>
<span class="linenos">86</span>                    <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"Wo_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">87</span>                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"bo_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">88</span>                <span class="p">)</span>
<span class="linenos">89</span>                <span class="n">c_bar</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span>
<span class="linenos">90</span>                    <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"Wc_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">91</span>                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"bc_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
<span class="linenos">92</span>                <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-21">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-21">#</a>
                </div>
                <p>New memory cell and hidden state</p>
<p>\(
\begin{aligned}
C_t &amp;= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t \\[1ex]
h_t &amp;= o_t \odot \tanh(C_t)
\end{aligned}
\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">93</span>                <span class="n">c</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">c_prev</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">c_bar</span>
<span class="linenos">94</span>                <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">tanh</span><span class="p">(</span><span class="n">c</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-22">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-22">#</a>
                </div>
                <p>Classification head</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">95</span>                <span class="k">if</span> <span class="n">cell_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">96</span>                    <span class="n">logits</span> <span class="o">=</span> <span class="n">h</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"W_head"</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"b_head"</span><span class="p">]</span>
<span class="linenos">97</span>                    <span class="n">probs</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">98</span>                    <span class="n">outputs</span><span class="p">[:,</span> <span class="n">timestep</span><span class="p">]</span> <span class="o">=</span> <span class="n">probs</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-23">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-23">#</a>
                </div>
                <p>Update the state for the next timestep</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos"> 99</span>                <span class="n">state</span><span class="p">[</span><span class="s2">"c"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
<span class="linenos">100</span>                <span class="n">state</span><span class="p">[</span><span class="s2">"h"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
<span class="linenos">101</span>                <span class="n">features</span> <span class="o">=</span> <span class="n">h</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-24">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-24">#</a>
                </div>
                <p>Save the activations for backpropagation</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">102</span>                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
<span class="linenos">103</span>                    <span class="p">[</span><span class="s2">"x"</span><span class="p">,</span> <span class="s2">"f"</span><span class="p">,</span> <span class="s2">"o"</span><span class="p">,</span> <span class="s2">"c_bar"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">,</span> <span class="s2">"h"</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">c_bar</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">]</span>
<span class="linenos">104</span>                <span class="p">):</span>
<span class="linenos">105</span>                    <span class="n">activations</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">timestep</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-25">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-25">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">106</span>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">activations</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-26">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-26">#</a>
                </div>
                <p>Alias for the forward method, similar to PyTorch's <code>nn.Module</code>.
This enables <code>model(inputs)</code> \(\equiv\) <code>model.forward(inputs)</code></p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">107</span>    <span class="fm">__call__</span> <span class="o">=</span> <span class="n">forward</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-27">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-27">#</a>
                </div>
                <p>Backward pass to compute the gradients.</p>
<ul>
<li><code>grad</code>: Gradient of the loss with respect to the output of the model, i.e. logits (pre-softmax scores)</li>
<li><code>activations</code>: Activations from the forward pass.</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">108</span>    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">activations</span><span class="p">):</span>
<span class="linenos">109</span>        <span class="n">batch_sz</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-28">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-28">#</a>
                </div>
                <p>Intialize the gradients of the next timestep to zeros. This will be updated as we move backward in time.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">110</span>        <span class="n">grad_next</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">111</span>            <span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">batch_sz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
<span class="linenos">112</span>            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"h"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">]</span>
<span class="linenos">113</span>        <span class="p">}</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-29">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-29">#</a>
                </div>
                <p>Helper function to compute the gradients of the linear layer.
The gradients are computed with respect to the input, weights, and biases respectively.</p>
<ul>
<li><code>X</code>: Input to the linear layer</li>
<li><code>W</code>: Weights of the linear layer</li>
<li><code>dY</code>: Gradient of the loss with respect to the output of the linear layer</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">114</span>        <span class="k">def</span> <span class="nf">_lin_grad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">dY</span><span class="p">):</span>
<span class="linenos">115</span>            <span class="k">return</span> <span class="p">(</span><span class="n">dY</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">dY</span><span class="p">,</span> <span class="n">dY</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-30">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-30">#</a>
                </div>
                <p>Backpropagation through time</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">116</span>        <span class="k">for</span> <span class="n">timestep</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-31">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-31">#</a>
                </div>
                <p>Classification head</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">117</span>            <span class="n">dout_t</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[:,</span> <span class="n">timestep</span><span class="p">]</span>
<span class="linenos">118</span>            <span class="n">h_t</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="s2">"h"</span><span class="p">][</span><span class="n">timestep</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-32">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-32">#</a>
                </div>
                <p>\(\text{logits}_t = h_t \mathbf{W}_{\text{head}} + \mathbf{b}_{\text{head}}\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">119</span>            <span class="n">dh_t</span><span class="p">,</span> <span class="n">dW_head</span><span class="p">,</span> <span class="n">db_head</span> <span class="o">=</span> <span class="n">_lin_grad</span><span class="p">(</span>
<span class="linenos">120</span>                <span class="n">X</span><span class="o">=</span><span class="n">h_t</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="s2">"W_head"</span><span class="p">],</span> <span class="n">dY</span><span class="o">=</span><span class="n">dout_t</span>
<span class="linenos">121</span>            <span class="p">)</span>
<span class="linenos">122</span>            <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="sa">f</span><span class="s2">"W_head"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dW_head</span>
<span class="linenos">123</span>            <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="sa">f</span><span class="s2">"b_head"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">db_head</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-33">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-33">#</a>
                </div>
                <p>Iterate over the LSTM cells in reverse order</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">124</span>            <span class="k">for</span> <span class="n">cell_idx</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">)):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-34">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-34">#</a>
                </div>
                <p>Get the activations for the current timestep</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">125</span>                <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">c_bar</span><span class="p">,</span> <span class="n">c_t</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos">126</span>                    <span class="n">activations</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">timestep</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span>
<span class="linenos">127</span>                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"x"</span><span class="p">,</span> <span class="s2">"f"</span><span class="p">,</span> <span class="s2">"o"</span><span class="p">,</span> <span class="s2">"c_bar"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">]</span>
<span class="linenos">128</span>                <span class="p">)</span>
<span class="linenos">129</span>                <span class="n">c_p</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="s2">"c"</span><span class="p">][</span><span class="n">timestep</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-35">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-35">#</a>
                </div>
                <p>Gradients flowing from the next timestep. The gradient of the hidden state \(h_t\) is the sum of
the gradients from the next cell and the next timestep.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">130</span>                <span class="n">dh_t</span> <span class="o">+=</span> <span class="n">grad_next</span><span class="p">[</span><span class="s2">"h"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span>
<span class="linenos">131</span>                <span class="n">dc_t</span> <span class="o">=</span> <span class="n">grad_next</span><span class="p">[</span><span class="s2">"c"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-36">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-36">#</a>
                </div>
                <p>\(h_t = o * tanh(c_t)\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">132</span>                <span class="n">do</span> <span class="o">=</span> <span class="n">dh_t</span> <span class="o">*</span> <span class="n">tanh</span><span class="p">(</span><span class="n">c_t</span><span class="p">)</span>
<span class="linenos">133</span>                <span class="n">dc_t</span> <span class="o">=</span> <span class="n">dh_t</span> <span class="o">*</span> <span class="n">o</span> <span class="o">*</span> <span class="n">tanh</span><span class="p">(</span><span class="n">c_t</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-37">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-37">#</a>
                </div>
                <p>\(c_t = f \times c_p + (1 - f) \times c_{\text{bar}}\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">134</span>                <span class="n">df</span> <span class="o">=</span> <span class="n">dc_t</span> <span class="o">*</span> <span class="p">(</span><span class="n">c_p</span> <span class="o">-</span> <span class="n">c_bar</span><span class="p">)</span>
<span class="linenos">135</span>                <span class="n">dc_p</span> <span class="o">=</span> <span class="n">dc_t</span> <span class="o">*</span> <span class="n">f</span>
<span class="linenos">136</span>                <span class="n">dc_bar</span> <span class="o">=</span> <span class="n">dc_t</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-38">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-38">#</a>
                </div>
                <p>Pre-activation gradients</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">137</span>                <span class="n">dc_bar</span> <span class="o">*=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">c_bar</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">138</span>                <span class="n">do</span> <span class="o">*=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">139</span>                <span class="n">df</span> <span class="o">*=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-39">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-39">#</a>
                </div>
                <p><code>f</code>, <code>o</code>, <code>c</code> Gates
Since all the gates are linear operations, the calculation will be similar</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">140</span>                <span class="n">dinp</span><span class="p">,</span> <span class="n">dh_prev</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
<span class="linenos">141</span>                <span class="k">for</span> <span class="n">gate</span><span class="p">,</span> <span class="n">doutput</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s2">"f"</span><span class="p">,</span> <span class="s2">"o"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="p">[</span><span class="n">df</span><span class="p">,</span> <span class="n">do</span><span class="p">,</span> <span class="n">dc_bar</span><span class="p">]):</span>
<span class="linenos">142</span>                    <span class="n">dX</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">_lin_grad</span><span class="p">(</span>
<span class="linenos">143</span>                        <span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="sa">f</span><span class="s2">"W</span><span class="si">{</span><span class="n">gate</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">],</span> <span class="n">dY</span><span class="o">=</span><span class="n">doutput</span>
<span class="linenos">144</span>                    <span class="p">)</span>
<span class="linenos">145</span>                    <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="sa">f</span><span class="s2">"W</span><span class="si">{</span><span class="n">gate</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dW</span>
<span class="linenos">146</span>                    <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="sa">f</span><span class="s2">"b</span><span class="si">{</span><span class="n">gate</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cell_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos">147</span>                    <span class="n">dinp_gate</span><span class="p">,</span> <span class="n">dh_prev_gate</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos">148</span>                        <span class="n">dX</span><span class="p">[:,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
<span class="linenos">149</span>                        <span class="n">dX</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="p">:],</span>
<span class="linenos">150</span>                    <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-40">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-40">#</a>
                </div>
                <p>Accumulate the gradients for the input and the hidden state,
since they are shared between the gates</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">151</span>                    <span class="n">dinp</span> <span class="o">+=</span> <span class="n">dinp_gate</span>
<span class="linenos">152</span>                    <span class="n">dh_prev</span> <span class="o">+=</span> <span class="n">dh_prev_gate</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-41">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-41">#</a>
                </div>
                <p>Update the gradients for the previous timestep</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">153</span>                <span class="n">dh_t</span> <span class="o">=</span> <span class="n">dinp</span>
<span class="linenos">154</span>                <span class="n">grad_next</span><span class="p">[</span><span class="s2">"c"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">dc_p</span>
<span class="linenos">155</span>                <span class="n">grad_next</span><span class="p">[</span><span class="s2">"h"</span><span class="p">][</span><span class="n">cell_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">dh_prev</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-42">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-42">#</a>
                </div>
                <p>Embedding layer</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">156</span>            <span class="n">word_indices</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="s2">"input"</span><span class="p">][</span><span class="n">timestep</span><span class="p">]</span>
<span class="linenos">157</span>            <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">][</span><span class="n">word_indices</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dinp</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-43">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-43">#</a>
                </div>
                <p>Helper method to serialize the model state, similar to PyTorch's <code>state_dict</code>.
The state dictionary contains the model configuration, weights, and gradients.
It can be used to save and load the model.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">158</span>    <span class="nd">@property</span>
<span class="linenos">159</span>    <span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">160</span>        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
<span class="linenos">161</span>            <span class="n">config</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<span class="linenos">162</span>                <span class="n">embed_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span>
<span class="linenos">163</span>                <span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
<span class="linenos">164</span>                <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
<span class="linenos">165</span>                <span class="n">n_cells</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span>
<span class="linenos">166</span>            <span class="p">),</span>
<span class="linenos">167</span>            <span class="n">weights</span><span class="o">=</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span>
<span class="linenos">168</span>            <span class="n">grad</span><span class="o">=</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">),</span>
<span class="linenos">169</span>        <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="lstm-44">
            <div class="docs">
                <div class="section-link">
                    <a href="#lstm-44">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">170</span>    <span class="nd">@classmethod</span>
<span class="linenos">171</span>    <span class="k">def</span> <span class="nf">from_state_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
<span class="linenos">172</span>        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">"config"</span><span class="p">])</span>
<span class="linenos">173</span>        <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
<span class="linenos">174</span>            <span class="p">[</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">"weights"</span><span class="p">],</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">"grad"</span><span class="p">]],</span>
<span class="linenos">175</span>            <span class="p">[</span><span class="n">obj</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="n">grad</span><span class="p">],</span>
<span class="linenos">176</span>        <span class="p">):</span>
<span class="linenos">177</span>            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">src</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span class="linenos">178</span>                <span class="n">tgt</span><span class="p">[</span><span class="n">k</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">v</span>
<span class="linenos">179</span>        <span class="k">return</span> <span class="n">obj</span></pre></div>

            </div>
        </div>
    
        </div>
    
</div>
</div>
</section>
</section>
<section id="activation-and-loss-functions" class="level2 page-columns page-full" data-number="3">
<h2 data-number="3" data-anchor-id="activation-and-loss-functions"><span class="header-section-number">3</span> Activation and Loss Functions</h2>
<p>The activation functions used in LSTM are the sigmoid, tanh (hyperbolic tangent), and softmax functions.</p>
<ul>
<li><code>Sigmoid</code> is used to compute the gates, which are values between 0 and 1 that control the flow of information.<br>
</li>
<li><code>tanh</code> function is used to compute the candidate memory state.<br>
</li>
<li><code>Softmax</code> is used to compute the output probabilities.</li>
</ul>
<p>The loss function used is the cross-entropy loss, which is suitable for classification tasks. Next token prediction is indeed a classification task where the model predicts the probability distribution over the vocabulary for the next token in the sequence.</p>
<div id="cell-8" class="cell page-columns page-full" data-execution_count="5">
<div class="cell-output cell-output-display column-page">
<h3>op.py</h3>
        <div class="docfuse ">
            
        <div class="section" id="op-0">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-0">#</a>
                </div>
                <p><strong>Sigmoid function</strong></p>
<p>The sigmoid squashes the input to the range [0, 1].</p>
<ul>
<li>If the flag <code>grad</code> is <code>False</code>, returns the sigmoid of <code>x</code>: $$\sigma(x) = \frac{1}{1 + e^{-x}}$$</li>
<li>Otherwise, \(x = \sigma(z)\) and the derivate \(\frac{\partial \sigma(z)}{\partial z}\) is returned:
$$\frac{\partial \sigma(z)}{\partial z} = \sigma(z) * (1 - \sigma(z))= x(1-x)$$.</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">1</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos">2</span>
<span class="linenos">3</span>
<span class="linenos">4</span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="linenos">5</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">grad</span><span class="p">:</span>
<span class="linenos">6</span>        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="linenos">7</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-1">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-1">#</a>
                </div>
                <p><strong>Hyperbolic tangent function</strong></p>
<p>The <code>tanh</code> function squashes the input to the range [-1, 1]. It's defined as:
$$\tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos"> 8</span><span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="linenos"> 9</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">grad</span><span class="p">:</span>
<span class="linenos">10</span>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="kp">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">11</span>    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-2">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-2">#</a>
                </div>
                <p><strong>Softmax function</strong></p>
<p>Applies the softmax function to the input array along the specified axis. Softmax converts
a vector of real numbers into a probability distribution. The logits are first exponentiated
to make them positive and increase their separation. It's defined as:
$$\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$$</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">12</span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-3">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-3">#</a>
                </div>
                <p>Subtracting the maximum value for numerical stability. Softmax is invariant to to a constant shift</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">13</span>    <span class="n">exps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="kp">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="linenos">14</span>    <span class="k">return</span> <span class="n">exps</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-4">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-4">#</a>
                </div>
                <p><strong>Cross-entropy loss function</strong></p>
<p>Computes the cross-entropy loss between the predicted and target distributions. The cross-entropy loss is defined as:
$$H(y, p) = -\sum_{i} y_i \log(p_i)$$</p>
<ul>
<li><code>prediction</code>: The predicted array of probabilities of shape <code>(batch_size, num_classes)</code>.</li>
<li><code>target</code>: The target array of shape <code>(batch_size,)</code> containing the class indices.</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">15</span><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">"mean"</span><span class="p">):</span>
<span class="linenos">16</span>    <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">finfo</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
<span class="linenos">17</span>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">clip</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-5">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-5">#</a>
                </div>
                <p>Take the negative log of the predicted probability of the target class</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">18</span>    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span>
<span class="linenos">19</span>        <span class="n">np</span><span class="o">.</span><span class="kp">log</span><span class="p">(</span><span class="n">prediction</span><span class="p">),</span> <span class="n">target</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="kp">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span>
<span class="linenos">20</span>    <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="op-6">
            <div class="docs">
                <div class="section-link">
                    <a href="#op-6">#</a>
                </div>
                <p>Aggregate the loss</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">21</span>    <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">"mean"</span><span class="p">:</span>
<span class="linenos">22</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="linenos">23</span>    <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">"sum"</span><span class="p">:</span>
<span class="linenos">24</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="linenos">25</span>    <span class="k">return</span> <span class="n">loss</span></pre></div>

            </div>
        </div>
    
        </div>
    
</div>
</div>
</section>
<section id="adamw" class="level2 page-columns page-full" data-number="4">
<h2 data-number="4" data-anchor-id="adamw"><span class="header-section-number">4</span> AdamW</h2>
<p>AdamW is a variant of the Adam optimizer that decouples weight penalty from the optimization steps, where the weight penalty is applied directly to the gradients. Adam optimizer uses both the first and second moments of the gradients to adapt the learning rate tailored to each parameter. The benefit of Adam/AdamW is that it requires little tuning of hyperparameters compared to RMSprop and SGD. Weâ€™ll go over each step of the optimization in the implementation.</p>
<div id="cell-11" class="cell page-columns page-full" data-execution_count="6">
<div class="cell-output cell-output-display column-page">
<h3>optim.py</h3>
        <div class="docfuse ">
            
        <div class="section" id="optim-0">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-0">#</a>
                </div>
                <p>Import <code>NumPy</code></p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">1</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-1">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-1">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">2</span><span class="k">class</span> <span class="nc">AdamW</span><span class="p">:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-2">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-2">#</a>
                </div>
                <h3>AdamW Optimizer</h3>
<p>Parameters:</p>
<ul>
<li><code>params</code> (dict): Dictionary referencing the model parameters</li>
<li><code>grads</code> (dict): Dictionary referencing the gradients of the model parameters</li>
<li><code>lr</code> (float): Learning rate</li>
<li><code>betas</code> (Tuple[float, float]): Coefficients used for computing running averages of gradient and its square</li>
<li><code>eps</code> (float): Term added to the denominator to improve numerical stability</li>
<li><code>weight_decay</code> (float): Weight decay (L2 penalty) coefficient</li>
<li><code>amsgrad</code> (bool): Whether to use the AMSGrad variant of the algorithm</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos"> 3</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<span class="linenos"> 4</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 5</span>        <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="linenos"> 6</span>        <span class="n">grads</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="linenos"> 7</span>        <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
<span class="linenos"> 8</span>        <span class="n">betas</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
<span class="linenos"> 9</span>        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
<span class="linenos">10</span>        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
<span class="linenos">11</span>        <span class="n">amsgrad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos">12</span>    <span class="p">):</span>
<span class="linenos">13</span>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
<span class="linenos">14</span>        <span class="bp">self</span><span class="o">.</span><span class="n">grads</span> <span class="o">=</span> <span class="n">grads</span>
<span class="linenos">15</span>        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
<span class="linenos">16</span>        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
<span class="linenos">17</span>        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
<span class="linenos">18</span>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
<span class="linenos">19</span>        <span class="bp">self</span><span class="o">.</span><span class="n">amsgrad</span> <span class="o">=</span> <span class="n">amsgrad</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-3">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-3">#</a>
                </div>
                <p>Counter for the number of iterations</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">20</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span> <span class="o">=</span> <span class="mi">0</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-4">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-4">#</a>
                </div>
                <p>Initialize first moment vector (mean of gradients) for each parameter</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">21</span>        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-5">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-5">#</a>
                </div>
                <p>Initialize second moment vector (uncentered variance of gradients) for each parameter</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">22</span>        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-6">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-6">#</a>
                </div>
                <p>Initialize maximum of second moment vector for AMSGrad if needed</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">23</span>        <span class="bp">self</span><span class="o">.</span><span class="n">v_m</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos">24</span>            <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="linenos">25</span>            <span class="k">if</span> <span class="n">amsgrad</span>
<span class="linenos">26</span>            <span class="k">else</span> <span class="kc">None</span>
<span class="linenos">27</span>        <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-7">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-7">#</a>
                </div>
                <p>Resets all gradients to zero. This is typically used before computing new
gradients in the training loop.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">28</span>    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">29</span>        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">grads</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span class="linenos">30</span>            <span class="n">v</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-8">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-8">#</a>
                </div>
                <p>Perform a single optimization step.</p>
<p>Updates the parameters of the model using the AdamW update rule, which
includes bias correction, optional AMSGrad, and weight decay.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">31</span>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-9">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-9">#</a>
                </div>
                <p>Increment the iteration counter</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">32</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span> <span class="o">+=</span> <span class="mi">1</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-10">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-10">#</a>
                </div>
                <p>Unpack the beta values</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">33</span>        <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-11">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-11">#</a>
                </div>
                <p>Iterate over the parameters and their gradients</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">34</span>        <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">),</span> <span class="n">grad</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
<span class="linenos">35</span>            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">grads</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="linenos">36</span>        <span class="p">):</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-12">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-12">#</a>
                </div>
                <p>Update the first moment estimate:
$$m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$
where \(\beta_1\) is the exponential decay rate for the first moment estimates,
and \(g_t\) is the gradient at time step \(t\).  <br>
\(m_{t}\) is simply an exponential moving average (EMA) of the past gradients.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">37</span>            <span class="n">m_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-13">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-13">#</a>
                </div>
                <p>Update the second moment estimate:
$$v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2$$
where \(\beta_2\) is the exponential decay rate for the second moment estimates.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">38</span>            <span class="n">v_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
<span class="linenos">39</span>                <span class="n">grad</span><span class="o">**</span><span class="mi">2</span>
<span class="linenos">40</span>            <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-14">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-14">#</a>
                </div>
                <p>Compute bias-corrected first moment estimate:
$$\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$$</p>
<p>Without correction, the bias causes the algorithm to move very slowly at the beginning of training,
as the moment estimates are underestimated. In the early iterations, \(t\) is small, so \(\beta_1^t\) is close to 1,
making \(1 - \beta_1^t\) a small number. Dividing by this small number effectively increases the estimate.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">41</span>            <span class="n">m_t_hat</span> <span class="o">=</span> <span class="n">m_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-15">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-15">#</a>
                </div>
                <p>Compute bias-corrected second moment estimate:
$$\hat{v}_t = \frac{v_t}{1 - \beta_2^t}$$</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">42</span>            <span class="n">v_t_hat</span> <span class="o">=</span> <span class="n">v_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iters</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-16">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-16">#</a>
                </div>
                <p>AMSGrad update:
$$\hat{v}_t = \max(\hat{v}_t, v_{t-1})$$
where \(v_{t-1}\) is the previous second moment estimate.
This ensures \(v_t\) is always non-decreasing, preventing the learning rate from growing too large.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">43</span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">amsgrad</span><span class="p">:</span>
<span class="linenos">44</span>                <span class="n">v_t_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_m</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_m</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">v_t_hat</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-17">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-17">#</a>
                </div>
                <p>Adjusted gradient:
$$\hat{g} = \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$
where \(\epsilon\) is a small constant to avoid division by zero.  <br>
\(\frac{\hat{m}_t}{\sqrt{\hat{v}_t}}\) can be thought of as the <strong>signal-to-noise</strong> ratio of the gradient.
I'll leave the intuition behind this to another blog post.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">45</span>            <span class="n">g_hat</span> <span class="o">=</span> <span class="n">m_t_hat</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">sqrt</span><span class="p">(</span><span class="n">v_t_hat</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-18">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-18">#</a>
                </div>
                <p>Add weight penalty to the update:
$$\text{update} = \hat{g} + \lambda \cdot p$$
where \(\lambda\) is the <code>weight_decay</code> coefficient.
This is equivalent to adding the L2 penalty to the loss function, which penalizes large weights.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">46</span>            <span class="n">update</span> <span class="o">=</span> <span class="n">g_hat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">*</span> <span class="n">param</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="optim-19">
            <div class="docs">
                <div class="section-link">
                    <a href="#optim-19">#</a>
                </div>
                <p>Update the parameters in the direction of the negative gradient, scaled by the learning rate:
$$ p_t = p_{t-1} - \eta \cdot \text{update}$$
where \(p_{t-1}\) is the previous parameter value.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">47</span>            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">update</span></pre></div>

            </div>
        </div>
    
        </div>
    
</div>
</div>
</section>
<section id="data-utilities" class="level2 page-columns page-full" data-number="5">
<h2 data-number="5" data-anchor-id="data-utilities"><span class="header-section-number">5</span> Data Utilities</h2>
<p>In this section weâ€™ll implement the Dataset and Dataloader classes to handle the Shakespeare dataset. We follow the best practices of PyTorchâ€™s <strong>Dataset</strong> and <strong>DataLoader</strong> classes to make the implementation more modular and reusable.</p>
<ul>
<li>The <code>Dataset</code> class implements the <code>__getitem__</code> method, which returns a single sample from the dataset.</li>
<li>The <code>DataLoader</code> class will be used to sample mini-batches from the dataset, by calling the <code>__getitem__</code> method of the <code>Dataset</code>.</li>
</ul>
<div id="cell-14" class="cell page-columns page-full" data-execution_count="7">
<div class="cell-output cell-output-display column-page">
<h3>data.py</h3>
        <div class="docfuse ">
            
        <div class="section" id="data-0">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-0">#</a>
                </div>
                <p>Import NumPy</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">1</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-1">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-1">#</a>
                </div>
                <h3>Dataset</h3>
<p>A dataset for next character prediction tasks.</p>
<p>For a sequence of characters \([c_1, c_2, ..., c_n]\) and a given sequence length \(l\),
this dataset creates input/target pairs of the form:</p>
<ul>
<li>Input \(x_i\):  \([c_i, c_{i+1}, ..., c_{i+l-1}]\)</li>
<li>Target \(y_i\): \([c_{i+1}, c_{i+2}, ..., c_{i+l}]\)</li>
</ul>
<p>where \(i\) ranges from 1 to \(n-l\).</p>
<p>Each item in the dataset is a tuple \((x_i, y_i)\) where both \(x_i\) and \(y_i\) have length \(l\).
The task is to predict each character in \(y_i\) given the corresponding prefix in \(x_i\).</p>
<p>For example, given \(x_i = [c_i, c_{i+1}, c_{i+2}]\), the model would aim to predict:</p>
<ul>
<li>\(c_{i+1}\) given \([c_i]\)</li>
<li>\(c_{i+2}\) given \([c_i, c_{i+1}]\)</li>
<li>\(c_{i+3}\) given \([c_i, c_{i+1}, c_{i+2}]\)</li>
</ul>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">2</span><span class="k">class</span> <span class="nc">NextCharDataset</span><span class="p">:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-2">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-2">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">3</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
<span class="linenos">4</span>        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-3">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-3">#</a>
                </div>
                <p>Create a sliding window view of the data</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">5</span>        <span class="bp">self</span><span class="o">.</span><span class="n">window_view</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">sliding_window_view</span><span class="p">(</span>
<span class="linenos">6</span>            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">window_shape</span><span class="o">=</span><span class="n">seq_length</span> <span class="o">+</span> <span class="mi">1</span>
<span class="linenos">7</span>        <span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-4">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-4">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">8</span>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">9</span>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window_view</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-5">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-5">#</a>
                </div>
                <p>\(\text{Input}_i\):  \([c_i, c_{i+1}, ..., c_{i+l-1}]\)</p>
<p>\(\text{Target}_i\): \([c_{i+1}, c_{i+2}, ..., c_{i+l}]\)</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">10</span>    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="linenos">11</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_view</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_view</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="linenos">12</span>        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-6">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-6">#</a>
                </div>
                <h3>DataLoader</h3>
<p>A simple <code>DataLoader</code> to iterate over a dataset in batches.</p>

            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">13</span><span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-7">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-7">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">14</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="linenos">15</span>        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
<span class="linenos">16</span>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
<span class="linenos">17</span>        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
<span class="linenos">18</span>        <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="o">=</span> <span class="n">drop_last</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-8">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-8">#</a>
                </div>
                <p>The <code>__iter__</code> method returns an iterator that yields batches of data. It's mainly
used in a <code>for</code> loop to iterate over the dataset. e.g.:</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="o">...</span>
</pre></div>


            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">19</span>    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">20</span>        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="linenos">21</span>
<span class="linenos">22</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
<span class="linenos">23</span>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="linenos">24</span>
<span class="linenos">25</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span><span class="p">:</span>
<span class="linenos">26</span>            <span class="n">remainder</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
<span class="linenos">27</span>            <span class="k">if</span> <span class="n">remainder</span><span class="p">:</span>
<span class="linenos">28</span>                <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="n">remainder</span><span class="p">]</span>
<span class="linenos">29</span>
<span class="linenos">30</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
<span class="linenos">31</span>            <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
<span class="linenos">32</span>            <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">batch_indices</span><span class="p">]</span>
<span class="linenos">33</span>            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></pre></div>

            </div>
        </div>
    

        <div class="section" id="data-9">
            <div class="docs">
                <div class="section-link">
                    <a href="#data-9">#</a>
                </div>
                
            </div>
            <div class="code">
                <div class="highlight"><pre><span class="linenos">34</span>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">35</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span><span class="p">:</span>
<span class="linenos">36</span>            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
<span class="linenos">37</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">38</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="kp">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="linenos">39</span>
<span class="linenos">40</span>    <span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<span class="linenos">41</span>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
<span class="linenos">42</span>            <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="k">for</span> <span class="n">samples</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)]</span>
<span class="linenos">43</span>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
<span class="linenos">44</span>            <span class="k">return</span> <span class="p">{</span>
<span class="linenos">45</span>                <span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos">46</span>            <span class="p">}</span>
<span class="linenos">47</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">48</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></pre></div>

            </div>
        </div>
    
        </div>
    
</div>
</div>
</section>
<section id="training-on-shakespeare-dataset" class="level2" data-number="6">
<h2 data-number="6" data-anchor-id="training-on-shakespeare-dataset"><span class="header-section-number">6</span> Training on Shakespeare dataset</h2>
<p>Now itâ€™s time to put everything together and train the model on the a dataset. Weâ€™ll use the Shakespeare dataset, which consists of a collection of Shakespeareâ€™s plays. The model will be trained to predict the next character in the sequence given a sequence of characters.</p>
<p>An important distinction to make between the text generation at training time and inference time is that at training time, we feed the ground truth characters to the model to predict the next character; This is called <strong>teacher forcing</strong>. At inference time, we feed the modelâ€™s prediction at time step <span class="math inline">\(t\)</span> as the input at time step <span class="math inline">\(t+1\)</span> to predict the next character.</p>
<section id="load" class="level3" data-number="6.1">
<h3 data-number="6.1" data-anchor-id="load"><span class="header-section-number">6.1</span> Load</h3>
<div id="cell-18" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pylab <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Download the Shakespeare dataset which is a single text file from the following link: <a href="https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt">Shakespeare dataset</a></p>
<div id="cell-20" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"shakespeare.txt"</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> <span class="bu">file</span>.read()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell styled-output" data-execution_count="10">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[:<span class="dv">200</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?

All:
Resolved. resolved.

First Citizen:
First, you</code></pre>
</div>
</div>
</section>
<section id="preprocess" class="level3" data-number="6.2">
<h3 data-number="6.2" data-anchor-id="preprocess"><span class="header-section-number">6.2</span> Preprocess</h3>
<p>We need to convert the text data into numerical data. Using scikit-learnâ€™s <code>LabelEncoder</code> we can map each character to a unique integer. The same encoder will be used to inverse transform the predictions back to characters.</p>
<div id="cell-23" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>char_data <span class="op">=</span> np.array(<span class="bu">list</span>(data))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>indices_data <span class="op">=</span> encoder.fit_transform(char_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-24" class="cell styled-output" data-execution_count="12">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>vocabulary <span class="op">=</span> encoder.classes_</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>vocabulary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array(['\n', ' ', '!', '$', '&amp;', "'", ',', '-', '.', '3', ':', ';', '?',
       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],
      dtype='&lt;U1')</code></pre>
</div>
</div>
<p>An example of the mapped data:</p>
<div id="cell-26" class="cell styled-output" data-execution_count="13">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>indices_data[:<span class="dv">200</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,
       44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,
       52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,
       51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,
       54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,
       57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39,
       56, 43,  1, 39, 50, 50,  1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56,
       39, 58, 46, 43, 56,  1, 58, 53,  1, 42, 47, 43,  1, 58, 46, 39, 52,
        1, 58, 53,  1, 44, 39, 51, 47, 57, 46, 12,  0,  0, 13, 50, 50, 10,
        0, 30, 43, 57, 53, 50, 60, 43, 42,  8,  1, 56, 43, 57, 53, 50, 60,
       43, 42,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43,
       52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63, 53, 59])</code></pre>
</div>
</div>
</section>
<section id="initialize" class="level3" data-number="6.3">
<h3 data-number="6.3" data-anchor-id="initialize"><span class="header-section-number">6.3</span> Initialize</h3>
<p>Now letâ€™s define the dataloader, the model and the optimizer. I used the following hyperparameters below, but feel free to experiment with different values.</p>
<div id="cell-29" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>SEQUENCE_LENGTH <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>VOCAB_SIZE <span class="op">=</span> <span class="bu">len</span>(vocabulary)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>TRAIN_SPLIT <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>SHUFFLE_TRAIN <span class="op">=</span> <span class="va">True</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>EMBED_SIZE <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>HIDDEN_SIZE <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>NUM_LAYERS <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>NUM_EPOCHS <span class="op">=</span> <span class="dv">5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Define the train and test data loaders</p>
<div id="cell-31" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> data <span class="im">import</span> NextCharDataset, DataLoader</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>trainset_size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(indices_data) <span class="op">*</span> TRAIN_SPLIT)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> indices_data[:trainset_size]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> indices_data[trainset_size:]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> NextCharDataset(train_data, SEQUENCE_LENGTH)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>testset <span class="op">=</span> NextCharDataset(test_data, SEQUENCE_LENGTH)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(trainset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span>SHUFFLE_TRAIN)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(testset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Define the model and optimizer</p>
<div id="cell-33" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lstm <span class="im">import</span> LSTMClassifier</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> optim <span class="im">import</span> AdamW</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LSTMClassifier(EMBED_SIZE, HIDDEN_SIZE, VOCAB_SIZE, NUM_LAYERS)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(params<span class="op">=</span>model.layers, grads<span class="op">=</span>model.grad, lr<span class="op">=</span>LEARNING_RATE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-loop" class="level3" data-number="6.4">
<h3 data-number="6.4" data-anchor-id="training-loop"><span class="header-section-number">6.4</span> Training loop</h3>
<p>The training loop follows this standard structure:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="op">=</span> <span class="dv">1</span> to TOTAL_EPOCHS<span class="op">:</span>    </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Training Phase</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> each batch <span class="kw">in</span> train_data<span class="op">:</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="fu">forward_pass</span>(model<span class="op">,</span> batch)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="fu">compute_loss</span>(predictions<span class="op">,</span> true_labels)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        gradients <span class="op">=</span> <span class="fu">compute_gradients</span>(loss)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">update_model_parameters</span>(model<span class="op">,</span> gradients)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">record_metrics</span>(loss<span class="op">,</span> accuracy<span class="op">,</span> <span class="op">...</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Testing Phase</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> each batch <span class="kw">in</span> test_data<span class="op">:</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="fu">forward_pass</span>(model<span class="op">,</span> batch)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="fu">compute_loss</span>(predictions<span class="op">,</span> true_labels)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="fu">record_metrics</span>(loss<span class="op">,</span> accuracy<span class="op">,</span> <span class="op">...</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br><br>
Most of the implementation such as the forward and backward passes, optimization and data loading is already done. The remaining part is loss computation and gradient of loss w.r.t the predictions. Since next-token prediction is a classification task, weâ€™ll use the cross-entropy loss function.</p>
<div id="cell-36" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> op <span class="im">import</span> cross_entropy</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>train_losses <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>test_losses <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(NUM_EPOCHS), desc<span class="op">=</span><span class="st">"Epoch"</span>):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># training loop</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> inputs, targets <span class="kw">in</span> (pbar <span class="op">:=</span> tqdm(trainloader, leave<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> SHUFFLE_TRAIN:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        probabilities, state, activations <span class="op">=</span> model.forward(inputs, state)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># cross entropy loss</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> cross_entropy(probabilities, targets)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># accuracy</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> np.mean(np.argmax(probabilities, axis<span class="op">=-</span><span class="dv">1</span>) <span class="op">==</span> targets)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># loss gradient w.r.t logits (before softmax)</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> np.copy(probabilities)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Subtract 1 from the probabilities of the true classes</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Since the gradient is p_i - y_i</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        gradient[np.arange(targets.shape[<span class="dv">0</span>])[:, <span class="va">None</span>], </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>                 np.arange(targets.shape[<span class="dv">1</span>]), targets] <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Subtract 1 from the probabilities of the true classes</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">/=</span> gradient.shape[<span class="dv">0</span>]</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># backpropagate and update</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        model.backward(gradient, activations)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># log</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        pbar.set_postfix({<span class="st">"loss"</span>: <span class="ss">f"</span><span class="sc">{</span>loss<span class="sc">:.5f}</span><span class="ss">"</span>, </span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"accuracy"</span>: <span class="ss">f"</span><span class="sc">{</span>accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">"</span>})</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>        train_losses[epoch].append(loss)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># testing loop</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>    loss_sum <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>    accuracy_sum <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">iter</span>, (inputs, targets) <span class="kw">in</span> (pbar <span class="op">:=</span> tqdm(<span class="bu">enumerate</span>(testloader),</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>                                                 leave<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>        probabilities, state, _ <span class="op">=</span> model.forward(</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>            inputs, state<span class="op">=</span><span class="va">None</span>, teacher_forcing<span class="op">=</span><span class="va">False</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> cross_entropy(probabilities, targets)</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> np.mean(np.argmax(probabilities, axis<span class="op">=-</span><span class="dv">1</span>) <span class="op">==</span> targets)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>        loss_sum <span class="op">+=</span> loss</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>        accuracy_sum <span class="op">+=</span> accuracy</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>        pbar.set_postfix(</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>                <span class="st">"loss"</span>: <span class="ss">f"</span><span class="sc">{</span>loss_sum <span class="op">/</span> (<span class="bu">iter</span> <span class="op">+</span> <span class="dv">1</span>)<span class="sc">:.5f}</span><span class="ss">"</span>,</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>                <span class="st">"accuracy"</span>: <span class="ss">f"</span><span class="sc">{</span>accuracy_sum <span class="op">/</span> (<span class="bu">iter</span> <span class="op">+</span> <span class="dv">1</span>)<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>        test_losses[epoch].append(loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br><br>
Now that itâ€™s time for training, the bad news is that the process will be slow! Understandably so, since weâ€™re using NumPy over CPU. Still, I trained the model for ~6000 iterations (batches) to make sure the implementation is correct and that the model is learning. The figure below shows the loss curve decreasing consistently over the iterations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/loss.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Training Loss Curve</figcaption>
</figure>
</div>
<p>For checkpointing, we can save the model to disk:</p>
<div id="cell-39" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>np.save(<span class="st">"checkpoint.npy"</span>, model.state_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To reload from the checkpoint, use the <code>from_state_dict</code> method:</p>
<div id="cell-41" class="cell styled-output" data-execution_count="51">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>state_dict <span class="op">=</span> np.load(<span class="st">"checkpoint.npy"</span>, allow_pickle<span class="op">=</span><span class="va">True</span>).item()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LSTMClassifier.from_state_dict(state_dict)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>state_dict.keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>dict_keys(['config', 'weights', 'grad'])</code></pre>
</div>
</div>
</section>
<section id="generating-text" class="level3" data-number="6.5">
<h3 data-number="6.5" data-anchor-id="generating-text"><span class="header-section-number">6.5</span> Generating text</h3>
<p>At inference time, we feed the model a prefix text and let it generate the next characters. We can control the number of characters to generate by setting the <code>generate_length</code> parameter in <code>forward</code>. I used <strong>greedy decoding</strong> to generate the text which works by selecting the character with the highest probability at each time step.</p>
<div id="cell-45" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">generate</span>(model, prefix: <span class="bu">str</span>, length: <span class="bu">int</span>):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> np.array(<span class="bu">list</span>(prefix))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> encoder.transform(inputs)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> inputs[np.newaxis]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    probabilities, state, _ <span class="op">=</span> model.forward(</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        inputs, state, teacher_forcing<span class="op">=</span><span class="va">False</span>, generation_length<span class="op">=</span>length</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> np.argmax(probabilities[<span class="dv">0</span>, <span class="bu">len</span>(prefix) <span class="op">-</span> <span class="dv">1</span> :], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> prefix <span class="op">+</span> <span class="st">""</span>.join(encoder.inverse_transform(tokens))</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-46" class="cell styled-output" data-execution_count="54">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generate(model, prefix<span class="op">=</span><span class="st">"I will"</span>, length<span class="op">=</span><span class="dv">400</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>I will rest blood that bear blood at all,
And stay the king to the consulships?

MENENIUS:
Nay, then he will stay the king to the cause of my son's exile is banished.

ROMEO:
And stay the common people: there is no need, that I may call thee back.

NORTHUMBERLAND:
Here comes the county strict ready to give me leave to see him as he fall be thine, my lord.

KING RICHARD II:
Norfolk, throw down the coronat</code></pre>
</div>
</div>
<p>Looks like the model was able to learn something! As an alternative to basic sampling, more advanced techniques like beam search, Top-K sampling, and nucleus sampling can significantly enhance the text generation quality but thatâ€™d be beyond the scope of this post.</p>
<p><br><br>
I hope you found this post helpful. If you have any questions or suggestions, feel free to leave a comment. Thanks for reading!</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-colah2015_lstm_architecture" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">C. Olah, <span>â€œUnderstanding LSTM networks.â€</span> <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="uri">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>, 2015.</div>
</div>
<div id="ref-Greff_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">K. Greff, R. K. Srivastava, J. Koutnik, B. R. Steunebrink, and J. Schmidhuber, <span>â€œLSTM: A search space odyssey,â€</span> <em>IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 28, no. 10, pp. 2222â€“2232, Oct. 2017, doi: <a href="https://doi.org/10.1109/tnnls.2016.2582924">10.1109/tnnls.2016.2582924</a>.</div>
</div>
<div id="ref-cs231n_rnn" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">CS231n, <span>â€œConvolutional neural networks for visual recognition.â€</span> <a href="https://cs231n.github.io/rnn/" class="uri">https://cs231n.github.io/rnn/</a>, 2023.</div>
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{sarang2024,
  author = {Sarang, Nima},
  title = {Implementing {Multi-Layer} {LSTM} and {AdamW} from {Scratch}
    Using {NumPy}},
  date = {2024-06-15},
  url = {https://www.nimasarang.com/blog/2024-06-15-lstm-from-scratch/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-sarang2024" class="csl-entry quarto-appendix-citeas" role="listitem">
<div class="">N.
Sarang, <span>â€œImplementing Multi-Layer LSTM and AdamW from Scratch
using NumPy.â€</span> [Online]. Available: <a href="https://www.nimasarang.com/blog/2024-06-15-lstm-from-scratch/">https://www.nimasarang.com/blog/2024-06-15-lstm-from-scratch/</a></div>
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/(?:www\.)?(nimasarang\.com)\/.*$");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="nsarang/nsarang.github.io" data-repo-id="R_kgDOMZYgPg" data-category="Announcements" data-category-id="DIC_kwDOMZYgPs4ChVIN" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="dark" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2024, Nima Sarang</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>
async function loadBodyWhenReady() {
    while (!document.body.classList.contains('quarto-light') && !document.body.classList.contains('quarto-dark')) {
        await new Promise(resolve => setTimeout(resolve, 50));
    }
    setTimeout(() => {
        document.body.style.visibility = "visible";
    }, 50); // Adjust the delay to allow for the dark mode to be loaded
}
loadBodyWhenReady();
</script>
<script src="../../_assets/docfuse/render.js"></script>




</body></html>